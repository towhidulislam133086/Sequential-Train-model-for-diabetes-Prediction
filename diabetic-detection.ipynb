{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb0af38",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-29T18:33:03.757466Z",
     "iopub.status.busy": "2023-03-29T18:33:03.757011Z",
     "iopub.status.idle": "2023-03-29T18:33:03.773587Z",
     "shell.execute_reply": "2023-03-29T18:33:03.772154Z"
    },
    "papermill": {
     "duration": 0.024575,
     "end_time": "2023-03-29T18:33:03.776726",
     "exception": false,
     "start_time": "2023-03-29T18:33:03.752151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/diabetes-dataset/pima-indians-diabetes.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/diabetes-dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825aaf5a",
   "metadata": {
    "papermill": {
     "duration": 0.001776,
     "end_time": "2023-03-29T18:33:03.780954",
     "exception": false,
     "start_time": "2023-03-29T18:33:03.779178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How to train model for diabetes prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131fdacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T18:33:03.787623Z",
     "iopub.status.busy": "2023-03-29T18:33:03.786741Z",
     "iopub.status.idle": "2023-03-29T18:33:37.229668Z",
     "shell.execute_reply": "2023-03-29T18:33:37.227959Z"
    },
    "papermill": {
     "duration": 33.449404,
     "end_time": "2023-03-29T18:33:37.232375",
     "exception": false,
     "start_time": "2023-03-29T18:33:03.782971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6  148  72  35    0  33.6  0.627  50\n",
      "0     1   85  66  29    0  26.6  0.351  31\n",
      "1     8  183  64   0    0  23.3  0.672  32\n",
      "2     1   89  66  23   94  28.1  0.167  21\n",
      "3     0  137  40  35  168  43.1  2.288  33\n",
      "4     5  116  74   0    0  25.6  0.201  30\n",
      "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
      "762  10  101  76  48  180  32.9  0.171  63\n",
      "763   2  122  70  27    0  36.8  0.340  27\n",
      "764   5  121  72  23  112  26.2  0.245  30\n",
      "765   1  126  60   0    0  30.1  0.349  47\n",
      "766   1   93  70  31    0  30.4  0.315  23\n",
      "\n",
      "[767 rows x 8 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "762    0\n",
      "763    0\n",
      "764    0\n",
      "765    1\n",
      "766    0\n",
      "Name: 1, Length: 767, dtype: int64\n",
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 2ms/step - loss: 10.1640 - accuracy: 0.6362\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 2.8648 - accuracy: 0.5215\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.0915 - accuracy: 0.4876\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.9256 - accuracy: 0.5489\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8523 - accuracy: 0.5698\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8040 - accuracy: 0.5841\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.5867\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7226 - accuracy: 0.6258\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.6402\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6310\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.6349\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6389\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.6480\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6675\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6532\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6649\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6780\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.6936\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6819\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6415\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6871\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6936\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6858\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.7040\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.6884\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6936\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6871\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6910\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6988\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7132\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6975\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.7093\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6975\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7145\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7236\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7197\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7158\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7223\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7014\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7288\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7249\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7106\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7184\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7027\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7249\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7392\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7106\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7327\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7158\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7171\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7379\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7223\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7171\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7471\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7392\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7379\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7249\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7458\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7119\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7236\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7497\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7223\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7419\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7145\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7119\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7301\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7275\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7432\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7353\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7379\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7275\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7392\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7510\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7458\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7210\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7327\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7379\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7445\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7197\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7484\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7301\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7432\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7405\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7301\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7288\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7549\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7405\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7523\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7484\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7445\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7484\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7549\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7405\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7458\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7392\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7497\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7627\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7549\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7653\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7471\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7523\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7458\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7575\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7353\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7549\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7562\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7458\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7484\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7340\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7353\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7510\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7601\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7458\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7314\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7510\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7484\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7353\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7575\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7549\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7523\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7575\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7497\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7523\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7562\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7588\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7484\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7666\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7536\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7327\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7679\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7536\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7484\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7614\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7562\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7575\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7562\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7523\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7666\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7705\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7575\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7666\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7497\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7627\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7666\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7679\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7666\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7640\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7562\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7836\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7588\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7771\n",
      "Accuracy: 77.71\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "'''\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#from numpy import loadtxt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "dataset = pd.read_csv('/kaggle/input/diabetes-dataset/pima-indians-diabetes.csv')\n",
    "x = dataset.iloc[:,0:8]\n",
    "y = dataset.iloc[:,8]\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x, y, epochs=150, batch_size=10)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "_, accuracy = model.evaluate(x, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.905624,
   "end_time": "2023-03-29T18:33:40.281241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-29T18:32:52.375617",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
